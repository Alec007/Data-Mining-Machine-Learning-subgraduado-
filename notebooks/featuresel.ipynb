{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESMA 4016\n",
    "### Feature Selection en Clasificacion Supervisada\n",
    "### Edgar Acuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uso de feature_selection de scikit-learn,  del modulo feature selction de Arizona State University y del modulo skrebate para feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I-Usando la prueba de Chi-Square para ver si hay independenia entre la feature y la clase. \n",
    "\n",
    "De preferencia los datos deben estar discretizados y ademas con dos clases es mejor\n",
    "\n",
    "Personalmente no la recomiendo porque la priueba de Chisquare es aproximada y no muy robusta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chi-Square usando el  modulo de Feature selction de Scikit-learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, SelectPercentile, f_classif, mutual_info_classif\n",
    "# load data\n",
    "url= \"http://academic.uprm.edu/eacuna/diabetes.dat\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = pd.read_table(url, names=names,header=None)\n",
    "y=data['class']\n",
    "X=data.iloc[:,0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Funcion auxiliar para discretizar cualquier columna de un dataframe\n",
    "def disc_col_ew(df,str,k,out):\n",
    "    df1=df[str]\n",
    "    bins=np.linspace(df1.min(), df1.max(),k)\n",
    "    if out==\"num\":\n",
    "        df1=pd.cut(df1,bins=bins,include_lowest=True, right=True,labels=False)\n",
    "    else:\n",
    "        bins[0]=float('-inf')\n",
    "        bins[k-1]=float('inf')\n",
    "        df1=pd.cut(df1,bins=bins,include_lowest=True, right=True)  \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# funcion auxiliar para detreminar el numero optimo de intervalos segun la formula de scott\n",
    "def nclass_scott(x):\n",
    "    h=3.5*(np.var(x,ddof=1)**.5)*len(x)**(-.3333)\n",
    "    intervals=m.ceil((max(x)-min(x))/h)\n",
    "    return int(intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Funcion para discretizar todas las colunan de un dataframe\n",
    "def disc_ew(df,out):\n",
    "    name=df.columns.tolist()\n",
    "    disc=pd.DataFrame()\n",
    "    for name in df.columns.tolist():\n",
    "        k=nclass_scott(df[name])\n",
    "        disc[name]=disc_col_ew(df,name,k,out)\n",
    "    return disc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discretizando las columnas de la matriz predictora X de diabetes\n",
    "diab_disc=disc_ew(X,out=\"num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 105.387  120.206    2.87    10.086   59.232   42.746   62.639  115.924]\n",
      "[[ 4 11  6]\n",
      " [ 0  6  2]\n",
      " [ 6 14  2]\n",
      " ..., \n",
      " [ 3  9  1]\n",
      " [ 0 10  5]\n",
      " [ 0  7  0]]\n"
     ]
    }
   ],
   "source": [
    "y1=y.as_matrix()\n",
    "X1=diab_disc.as_matrix()\n",
    "# feature extraction\n",
    "test = SelectKBest(score_func=chi2, k=3)\n",
    "fit = test.fit(X1, y1)\n",
    "# summarize scores\n",
    "np.set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "features= fit.transform(X1)\n",
    "# Imprime los datos de las tres mejores features\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comentario: Las tres mejores variables con la prueba de Chi-square son plas, age y preg por tener el Chi-Square mas alto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II-Usando la prueba de estadistica de F para comparar dos o mas grupos\n",
    "\n",
    "Se puede usar la libreria sciki-learn o la libreria de la ASU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.221  1.     0.027  0.034  0.084  0.378  0.14   0.253]\n",
      "[[ 148.    33.6   50. ]\n",
      " [  85.    26.6   31. ]\n",
      " [ 183.    23.3   32. ]\n",
      " ..., \n",
      " [ 121.    26.2   30. ]\n",
      " [ 126.    30.1   47. ]\n",
      " [  93.    30.4   23. ]]\n"
     ]
    }
   ],
   "source": [
    "# Selecion  de Features usando los p-values de la F-test como score\n",
    "# Aqui usamos sciji-learn y se selecciona el 30% de deatures con el mas alro score\n",
    "selector = SelectPercentile(f_classif, percentile=30)\n",
    "fit=selector.fit(X, y)\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "scores /= scores.max()\n",
    "print(scores)\n",
    "features= fit.transform(X)\n",
    "# Imprime los datos de las tres mejores features\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comentario: Las tres, mejores variables con la prueba de F son plas,mass y age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  33.622,  169.293,    1.286,    5.408,    8.295,   58.266,\n",
      "         12.778,   36.06 ]), array([1, 5, 7, 0, 6, 4, 3, 2], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "#Usando la libreria Feature selection de la ASU\n",
    "features, labels = X.values, data['class'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels)\n",
    "from skfeature.function.statistical_based import f_score\n",
    "scoref = f_score.f_score(X_train, y_train)\n",
    "idx = f_score.feature_ranking(scoref)\n",
    "print(scoref,idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comentario: las tres variables mas importantes con la prueba de F son: plas,mass y age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III- Usando Mutual Information (Entropia)\n",
    "\n",
    "Libreria scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.036  1.     0.041  0.008  0.322  0.649  0.073  0.433]\n"
     ]
    }
   ],
   "source": [
    "# Univariate feature selection with Mutual Information\n",
    "scores = mutual_info_classif(X,y)\n",
    "scores /= scores.max()\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comentario: Las tres variables usando el criterio de Mutual Information  son: plas, mass y age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IV-Usando ReliefF de la libreria skrebate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skrebate import ReliefF\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df=data.drop('class',axis=1)\n",
    "#Normalizando las predictoras\n",
    "df_norm=(df - df.min()) / (df.max() - df.min())\n",
    "features, labels = df_norm.values, data['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('preg', 29.500000000000011)\n",
      "('plas', 85.640703517587994)\n",
      "('pres', 14.201754385964897)\n",
      "('skin', 35.717171717171709)\n",
      "('test', 16.226359338061467)\n",
      "('mass', 42.022354694485877)\n",
      "('pedi', 15.458795900939359)\n",
      "('age', 27.358333333333324)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels)\n",
    "\n",
    "fs = ReliefF(n_neighbors=10)\n",
    "fs.fit(X_train, y_train)\n",
    "\n",
    "for feature_name, feature_score in zip(df.columns,fs.feature_importances_):\n",
    "    print (feature_name, feature_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comentario: las tres variables mas importantes con el ReliefF son: plas,mass y skin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  5.965,  16.247,   2.865,   6.428,   1.943,   6.396,   1.703,\n",
      "         2.683]), array([1, 3, 5, 0, 2, 7, 4, 6], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "#Usando la libreria feature selection de la ASU\n",
    "from skfeature.function.similarity_based import reliefF\n",
    "score_relief=reliefF.reliefF(X_train,y_train)\n",
    "feat=reliefF.feature_ranking(score_relief)\n",
    "print(score_relief,feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Comentario: las tres variables mas importantes con el RelieF son: plas, mass y skin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature scores for best three features (scored individually):\n",
      "0.036 plas\n",
      "0.026 age\n",
      "0.015 mass\n"
     ]
    }
   ],
   "source": [
    "#Usando el Relief de Orange\n",
    "import Orange\n",
    "df = Orange.data.Table(\"diabetes\")\n",
    "\n",
    "def print_best_3(ma):\n",
    "    for m in ma[:3]:\n",
    "        print \"%5.3f %s\" % (m[1], m[0])\n",
    "\n",
    "print 'Feature scores for best three features (scored individually):'\n",
    "#ReliefF usando 10 vecinos mas cercanos y  una muestrd m-100 para updating de los pesos\n",
    "meas = Orange.feature.scoring.Relief(k=10, m=100)\n",
    "mr = [ (a.name, meas(a, df)) for a in df.domain.attributes]\n",
    "mr.sort(key=lambda x: -x[1]) #sort decreasingly by the score\n",
    "print_best_3(mr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Usando el reliefF de la ASU\n",
    "#load data\n",
    "url= \"http://academic.uprm.edu/eacuna/bupa.dat\"\n",
    "names = ['mcv', 'alkphos', 'sgpt', 'aspar', 'gammagt', 'drinks', 'class']\n",
    "data = pd.read_table(url, names=names,header=None)\n",
    "y=data['class']\n",
    "X=data.iloc[:,0:6]\n",
    "y1=y.as_matrix()\n",
    "X1=X.as_matrix()\n",
    "features, labels = X.values, data['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  11. ,  -64.8,  309.4,  122. ,   -8.6,   39.7]), array([2, 3, 5, 0, 4, 1], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "score_relief=reliefF.reliefF(X_train,y_train)\n",
    "feat=reliefF.feature_ranking(score_relief)\n",
    "print(score_relief,feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "El Rielief de ASU recomienda  sgpt,aspar y drinks como las mejoras predictoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mcv', 2.7631578947368438)\n",
      "('alkphos', 0.37826086956521404)\n",
      "('sgpt', 4.0933333333333373)\n",
      "('aspar', 3.9480519480519489)\n",
      "('gammagt', 5.0136986301369877)\n",
      "('drinks', 4.1625000000000041)\n"
     ]
    }
   ],
   "source": [
    "fs = ReliefF(n_neighbors=10)\n",
    "fs.fit(X_train, y_train)\n",
    "\n",
    "for feature_name, feature_score in zip(data.columns,fs.feature_importances_):\n",
    "    print (feature_name, feature_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "El relielf de skrebate recomienda gammagt, sgpt y drinks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url='http://academic.uprm.edu/eacuna/landsat.txt'\n",
    "data = pd.read_table(url, header=None,delim_whitespace=True)\n",
    "y=data.iloc[:,36]\n",
    "X=data.iloc[:,0:37]\n",
    "y1=y.as_matrix()\n",
    "X1=X.as_matrix()\n",
    "features, labels = X.values, y.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  930709.18 ,  1262010.886,   892029.445,  1049502.413,\n",
      "         898223.814,  1153107.606,   823337.611,  1020532.51 ,\n",
      "         958491.233,  1260176.102,   872225.923,  1188106.014,\n",
      "         988273.692,  1302486.001,   888622.669,  1050787.881,\n",
      "         952157.203,  1254166.666,   842781.857,  1005976.002,\n",
      "         993024.781,  1307040.172,   792265.83 ,  1043069.516,\n",
      "        1002251.517,  1342077.748,   845803.286,  1062645.522,\n",
      "         934149.328,  1312146.663,   786174.152,   942112.38 ,\n",
      "         950935.431,  1296243.801,   839812.149,  1102420.276,   220117.875]), array([25, 29, 21, 13, 33,  1,  9, 17, 11,  5, 35, 27, 15,  3, 23,  7, 19,\n",
      "       24, 20, 12,  8, 16, 32, 31, 28,  0,  4,  2, 14, 10, 26, 18, 34,  6,\n",
      "       22, 30, 36], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "#usando Relief de la ASU\n",
    "score_relief=reliefF.reliefF(X_train,y_train)\n",
    "feat=reliefF.feature_ranking(score_relief)\n",
    "print(score_relief,feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
